{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91935d1",
   "metadata": {},
   "source": [
    "# Capstone Part 2c: Markov Chains Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28228ef",
   "metadata": {},
   "source": [
    "We now explore the predictive capabilities of a simple Markov Chains Model.\n",
    "\n",
    "Abstract: Markov Chains models a finite set of states with probabilities of going from one state to a next. For example, a model could have 2 possible follow-ups to the word \"a\" in \"I have a\": 0.5 chance of \"cat\" and 0.5 chance of \"dog\". A downside to Markov Chains is that it does not have \"memory\" of any sort. For a 1st order Markov Chains model, whenever the model runs into the word \"a\" it will still consider the next word to be either \"cat\" or \"dog\" regardless of its context.\n",
    "\n",
    "Compared to RNN and transformers, Markov Chains is an old method of text generation, considered almost obsolete at this point. However, there are upsides to this method as well which will be discussed in the results section.\n",
    "\n",
    "Reference: https://techeffigytutorials.blogspot.com/2015/01/markov-chains-explained.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f831c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a68db38",
   "metadata": {},
   "source": [
    "### Additional Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b166f0d",
   "metadata": {},
   "source": [
    "This is a character based Markov Chains model which works quite similarly to the LSTM model, except it works on simple probabilities it trains on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb35a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/enron6_clean.txt', 'r') as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaec0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.replace(\n",
    "    '\\n',' '\n",
    ").replace(\n",
    "    '?','.'\n",
    ").replace(\n",
    "    '!','.'\n",
    ").replace(\n",
    "    '“','.'\n",
    ").replace(\n",
    "    '”','.'\n",
    ").replace(\n",
    "    '/',' '\n",
    ").replace(\n",
    "    '‘',' '\n",
    ").replace(\n",
    "    '-',' '\n",
    ").replace(\n",
    "    '’',' '\n",
    ").replace(\n",
    "    '\\'',' '\n",
    ").replace(\n",
    "    '=', ' '\n",
    ").replace(\n",
    "    '\\\\', ' '\n",
    ").replace(\n",
    "    '_', ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0fec770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17219655"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9c607f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RTO   Grid South, SE Trans, SPP and Entergy Southeast RTO orders are out and have followed through with what we expected from the discussion at the FERC meeting. SPP and Entergy RTO proposals have been rejected because they fail to satisfy the scope and configuration requirements of Order No. . Commission notes that the required discussions between SPP and Entergy and its neighboring RTO TOs has led to no increase in the original scope and configuration. filings by SPP and Entergy were brief, indicating only a lack of interest by other RTOs or utilities in joining to enlarge scope; theyfailed to specify any details of the talks, what changes could be made or what could be fixed to accomodate combination with other RTOs. order states that the Commission favors the development of large, regional transmission organizations reflecting natural markets. Commission indicates that they favor four RTOs   NE, SE, MW and West. Therefore the order requires the participants in SPP and Entergy to pa'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a66271",
   "metadata": {},
   "source": [
    "### Functions Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde8bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stochastic matrix function\n",
    "def create_matrix(corpus, k=4): # k is chain order, default 4\n",
    "    T = {} # empty matrix\n",
    "    \n",
    "    for i in range(len(corpus)-k):\n",
    "        X = corpus[i:i+k] # slice k characters\n",
    "        Y = corpus[i+k] # the character after X\n",
    "        \n",
    "        if T.get(X) is None: # if X does not exist in matrix yet\n",
    "            T[X] = {} # create X key\n",
    "            T[X][Y] = 1 # create 1 instance of Y after X\n",
    "        else: \n",
    "            if T[X].get(Y) is None: # otherwise if Y value does not exist for X key\n",
    "                T[X][Y] = 1 # create 1 instance of Y after X\n",
    "            else: # otherwise...\n",
    "                T[X][Y] += 1 # add 1 instance of Y after X\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a41c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert frequency from stoc matrix to probabilities\n",
    "def freq2prob(T):     \n",
    "    for kx in T.keys():\n",
    "        s = float(sum(T[kx].values())) # sum of total frequencies\n",
    "        for k in T[kx].keys():\n",
    "            T[kx][k] = T[kx][k]/s # probability of frequency\n",
    "                \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd82ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "def model(corpus, k=4):\n",
    "    T = create_matrix(corpus, k)\n",
    "    T = freq2prob(T)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9692dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next(char, model, k): \n",
    "    char = char[-k:]\n",
    "    if model.get(char) is None: # if char not found in matrix\n",
    "        return \" \"\n",
    "    \n",
    "    possible_chars = list(model[char].keys()) # retrieve key from stoch matrix\n",
    "    possible_values = list(model[char].values()) # retrieve value from stoch matrix\n",
    " \n",
    "    return np.random.choice(possible_chars,p=possible_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c281d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sentence, k=4, max_len=5):    \n",
    "    char = sentence[-k:]    \n",
    "    for ix in range(max_len):\n",
    "        next_prediction = sample_next(char, model, k)\n",
    "        sentence += next_prediction\n",
    "        char = sentence[-k:]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed6426",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e7829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "model = model(corpus)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f30406b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.6802077293396"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85c231bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_next('Sout', model, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94304cd2",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de726a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new magic function to get samples with text in ipynb cell\n",
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "\n",
    "@register_line_magic\n",
    "def sample(line):\n",
    "    print(generate_text(line, k=4, max_len=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ee8e1",
   "metadata": {},
   "source": [
    "### Seeded Text Generation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0646f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PORT IDEAS FOR THE FINAL SECUTED. THE FINAL LOAD ID: ECT@ECT Submission metals Tradi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Let me know'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sample\n",
    "'Let me know'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be12873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Preferred by commended will contained With what is monumer said I want, sing the Independed to d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Regarding'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sample\n",
    "'Regarding'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe66a45",
   "metadata": {},
   "source": [
    "Applying it to text generation gives us a few words that still make sense (Let me know port ideas for the final...), but it quickly devolves into nonsense. This is to be expected from a model which operates purely on probabilistic behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc7c1c",
   "metadata": {},
   "source": [
    "### Topic-based Text Generation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1076e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Thanks, MN US to PG&E s Open t make it the addition. Budget in June that coller. Besses the $$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Financial'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sample\n",
    "'Financial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e96178f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Want telex : Wicketing the need to us this may very informal clearning impresentations from \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Meeting'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sample\n",
    "'Meeting'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab539a1b",
   "metadata": {},
   "source": [
    "Unsurprisingly, it does not perform well because there is no attention in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8019c75",
   "metadata": {},
   "source": [
    "### Word Autocompletion Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fce0092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sincerely, \n"
     ]
    }
   ],
   "source": [
    "print(generate_text('Sincer', k=4, max_len=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37bae22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regards, m\n"
     ]
    }
   ],
   "source": [
    "print(generate_text('Regar', k=4, max_len=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb36e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regards ha\n"
     ]
    }
   ],
   "source": [
    "print(generate_text('Regar', k=4, max_len=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c632e17",
   "metadata": {},
   "source": [
    "However, singular word autocompletion appears to be working rather well! Although several tries have to be performed in order to get the required output, it is still able to produce a word that has appeared in the corpus with just a few characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b8a6d",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Advantages of Markov Chains:\n",
    "\n",
    "1. It is rather easy to implement and trains extremely quickly (17.6802077293396 seconds).\n",
    "\n",
    "2. It is able to perform singular word autocompletion.\n",
    "\n",
    "3. It does not require any external libraries.\n",
    "\n",
    "\n",
    "Disadvantages of Markov Chains:\n",
    "\n",
    "1. It is rather fickle in the sense that it doesn't predict the required result every time. A custom temperature function could be implemented in order to control this but it kind of defeats the purpose of using a probabilistic model.\n",
    "\n",
    "2. It cannot generate coherent sentences well\n",
    "\n",
    "3. It is extremely subsceptible to noise. A perfect set of data is required to use it well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
