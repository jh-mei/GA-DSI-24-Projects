{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1d2a02",
   "metadata": {},
   "source": [
    "# Capstone Part 3: Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c59e96",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### LSTM RNN\n",
    "\n",
    "#### Pros:\n",
    "\n",
    "- Able to produce sentences with good grammatical quality\n",
    "\n",
    "- Generates text in no time\n",
    "\n",
    "#### Cons:\n",
    "\n",
    "- Takes very long to train\n",
    "\n",
    "- Produces incoherent sentences\n",
    "\n",
    "\n",
    "### Markov Chains\n",
    "\n",
    "#### Pros:\n",
    "\n",
    "- Able to perform word autocompletion\n",
    "\n",
    "- Generates text in no time\n",
    "\n",
    "- Doesn't require training\n",
    "\n",
    "#### Cons:\n",
    "\n",
    "- Cannot be used for text generation\n",
    "\n",
    "- Unreliable and random in terms of quality\n",
    "\n",
    "\n",
    "### GPT-2\n",
    "\n",
    "#### Pros:\n",
    "\n",
    "- Able to produce sentences with good grammatical quality\n",
    "\n",
    "- Able to pick up input topics and writing styles and reproduces them\n",
    "\n",
    "- Trains considerably quickly\n",
    "\n",
    "#### Cons:\n",
    "\n",
    "- Takes a while to generate text\n",
    "\n",
    "- Model size can get rather large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d9f6e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacebfa2",
   "metadata": {},
   "source": [
    "If this idea was to be implemented in DBS' infrastructure, GPT-2 would clearly be the way to go, maybe with Markov Chains to help with word autocompletion. \n",
    "\n",
    "However, we must also consider the time savings, which was the main issue of the problem statement. GPT-2 texts take around a minute to generate, for an average email-length text of 1000 characters. You also won't necessarily get a good enough email on the first go. \n",
    "\n",
    "In comparison, the average person types [200 characters a minute](https://en.wikipedia.org/wiki/Words_per_minute), which means that if the generated text isn't up to standards 5 times in a row, you would have been better off typing the email by yourself. \n",
    "\n",
    "Perhaps a more feasible idea would be to edit parts of a generated email manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba942f6",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8101a45",
   "metadata": {},
   "source": [
    "- Probably the immediate next step would be to try to improve the consistency of the results, be it increasing the temperature parameter which would reduce the randomness of output at a cost of quality, or fiddling more with the learning rate during finetuning. \n",
    "\n",
    "- Perhaps working with a larger portion of the Enron corpus would also be progress and should theoretically increase the consistency of writing style. \n",
    "\n",
    "- Finally, I could also try a different language model altogether, using a newer (and much larger) model like GPT-J."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
